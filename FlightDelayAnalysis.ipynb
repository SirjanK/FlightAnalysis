{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0fb0c6-760a-46e6-839d-c9af369228c4",
   "metadata": {},
   "source": [
    "# Flight Delay Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89a88851-c6b5-4475-9e43-fb322d5ef17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from typing import Optional\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3f66a-3763-404e-add3-cb76525989a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "path = 'notebook_data/*.csv'\n",
    "\n",
    "# Use glob to get all CSV file paths\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "# Read and concatenate all CSV files into a single DataFrame\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa119d-4a5c-48eb-a491-8c90fc83f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d541b-c849-4c3d-83ac-89f13cc8c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ORIGIN_CITY_NAME\"] == \"Milwaukee, WI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef36634-1526-4e55-8a90-063245882b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"ORIGIN_CITY_NAME\"] == \"Milwaukee, WI\") & (df[\"DAY_OF_MONTH\"] == 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be105cdf-7366-44ac-a821-9ebb2d5a31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of flights by day\n",
    "def get_num_flights(day, city):\n",
    "    return len(df[(df[\"ORIGIN_CITY_NAME\"] == city) & (df[\"DAY_OF_MONTH\"] == day)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bebc8b-eee6-4e71-b858-cd7c8f1d7cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Milwaukee, WI', 'San Diego, CA', 'San Francisco, CA']\n",
    "\n",
    "for city in cities:\n",
    "    days = range(1, 32)\n",
    "    num_flights = [get_num_flights(day, city) for day in days]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(days, num_flights, 'b-', label='Number of Flights')\n",
    "\n",
    "    # Mark day 24 with a red dot\n",
    "    plt.plot(24, get_num_flights(24, city), 'ro', markersize=10, label='XMas Eve')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(f'Number of Flights by Day of Month {city} December 2018-2023', fontsize=16)\n",
    "    plt.xlabel('Day of Month', fontsize=12)\n",
    "    plt.ylabel('Number of Flights', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "\n",
    "    # Set x-axis ticks to show all days\n",
    "    plt.xticks(days)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a735e3-6e55-4576-afa0-9b9f178a88df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delay_probability_with_cancellation(filtered_df, delay, city):\n",
    "    filtered_df = filtered_df[filtered_df[\"ORIGIN_CITY_NAME\"] == city]\n",
    "    num_delayed_or_cancelled = len(filtered_df[(filtered_df[\"ARR_DELAY\"] >= delay) | (filtered_df[\"CANCELLED\"] == True) | (filtered_df[\"DIVERTED\"] == True)])\n",
    "    return num_delayed_or_cancelled / len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2624cd6-9dc8-41d0-a547-e3e31cb58f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delay_probability_without_cancellation(filtered_df, delay, city):\n",
    "    filtered_df = filtered_df[filtered_df[\"ORIGIN_CITY_NAME\"] == city]\n",
    "    not_cancelled = filtered_df[(filtered_df[\"CANCELLED\"] == False) & (filtered_df[\"DIVERTED\"] == False)]\n",
    "    num_delayed = len(not_cancelled[(not_cancelled[\"ARR_DELAY\"] >= delay)])\n",
    "    return num_delayed / len(not_cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f98d7-cad5-44e3-b98c-150fe775c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Milwaukee, WI', 'San Diego, CA', 'San Francisco, CA']\n",
    "\n",
    "for city in cities:\n",
    "    filtered_df = df[df[\"ORIGIN_CITY_NAME\"] == city]\n",
    "    xmas_eve_df = filtered_df[filtered_df[\"DAY_OF_MONTH\"] == 24]\n",
    "    max_delay = 250  # override\n",
    "\n",
    "    delays = np.arange(0, max_delay + 1)\n",
    "\n",
    "    december_probabilities = [compute_delay_probability_without_cancellation(filtered_df, delay, city) for delay in delays]\n",
    "    xmas_eve_probabilities = [compute_delay_probability_without_cancellation(xmas_eve_df, delay, city) for delay in delays]\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(delays, december_probabilities, 'b-', label='December')\n",
    "    plt.plot(delays, xmas_eve_probabilities, 'r-', label='Xmas Eve')\n",
    "\n",
    "    december_prob_1h = december_probabilities[60]\n",
    "    xmas_eve_prob_1h = xmas_eve_probabilities[60]\n",
    "\n",
    "    plt.axhline(y=december_prob_1h, color='b', linestyle=':', xmin=0)\n",
    "    plt.axhline(y=xmas_eve_prob_1h, color='r', linestyle=':', xmin=0)\n",
    "\n",
    "    plt.plot(60, december_prob_1h, 'bo', markersize=8)\n",
    "    plt.plot(60, xmas_eve_prob_1h, 'ro', markersize=8)\n",
    "\n",
    "    plt.annotate(f'{december_prob_1h:.2%}', (60, december_prob_1h), xytext=(0, 10), \n",
    "                 textcoords='offset points', ha='center', va='bottom', color='b')\n",
    "    plt.annotate(f'{xmas_eve_prob_1h:.2%}', (60, xmas_eve_prob_1h), xytext=(0, 10), \n",
    "                 textcoords='offset points', ha='center', va='bottom', color='r')\n",
    "\n",
    "    plt.title(f'Delay Probability (without Cancellations) vs. Delay Duration {city} 2018-2023', fontsize=16)\n",
    "    plt.xlabel('Delay (hours:minutes)', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.ylim(0, 0.5)\n",
    "    plt.yticks(np.arange(0, 0.51, 0.1))\n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "    plt.legend(fontsize=10)\n",
    "\n",
    "    def format_time(x, pos):\n",
    "        hours = int(x // 60)\n",
    "        minutes = int(x % 60)\n",
    "        return f'{hours:02d}:{minutes:02d}'\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(format_time))\n",
    "    plt.xticks(np.arange(0, max_delay + 1, 30), rotation=45)\n",
    "\n",
    "    plt.xlim(0, max_delay * 1.05)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b61604-5b43-403a-81d6-9c78e139a904",
   "metadata": {},
   "source": [
    "## Analysis on Full Data\n",
    "We load the full data and investigate distributions of delays conditioned on various variables. Our goal is to find a generalized parameterized model for the delay distribution so that we can store the parameters for this model for each conditional.\n",
    "\n",
    "First, we look to prune the raw data (columns and rows) to what we minimally need. This logic will be ported to a file to cache pruned data. Then, we carry out analysis on the resulting df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data frame from all csv files in the data_dir\n",
    "def read_data(data_dir):\n",
    "    path = os.path.join(data_dir, '*.csv')\n",
    "    all_files = glob.glob(path)\n",
    "    return pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column bucketing the departure time into morning, afternoon, evening, and night\n",
    "# range left inclusive, right exclusive\n",
    "BUCKETS = {\n",
    "    'morning': (600, 1200),\n",
    "    'afternoon': (1200, 1800),\n",
    "    'evening': (1800, 2400),\n",
    "    'night': (0, 600),\n",
    "}\n",
    "\n",
    "def get_bucket(hour: Optional[float]) -> Optional[str]:\n",
    "    if hour is None:\n",
    "        return None\n",
    "    for bucket, (start, end) in BUCKETS.items():\n",
    "        if start <= hour < end:\n",
    "            return bucket\n",
    "\n",
    "df['DEP_TIME_BUCKET'] = df['CRS_DEP_TIME'].apply(get_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2684cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any cancelled or diverted flights\n",
    "filtered_df = df[(df['CANCELLED'] == 0) & (df['DIVERTED'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed1857",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02732697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the columns we need\n",
    "columns_needed = [\n",
    "    'OP_CARRIER_AIRLINE_ID',\n",
    "    'ORIGIN_AIRPORT_ID',\n",
    "    'DEST_AIRPORT_ID',\n",
    "    'DEP_TIME_BUCKET',\n",
    "    'ARR_DELAY',\n",
    "]\n",
    "\n",
    "filtered_df = filtered_df[columns_needed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any rows with missing values\n",
    "filtered_df = filtered_df.dropna()\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast the OP_CARRIER_AIRLINE_ID to int\n",
    "filtered_df['OP_CARRIER_AIRLINE_ID'] = filtered_df['OP_CARRIER_AIRLINE_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b475739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by col and gather counts. Order by greatest to least\n",
    "COL = 'DEP_TIME_BUCKET'\n",
    "counts = filtered_df.groupby(COL).size().sort_values(ascending=False)\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_CONDITIONAL_FILTER = 200\n",
    "# group by orig airport id and gather counts. filter out any airports with less than 200 flights\n",
    "orig_airport_counts = filtered_df.groupby('ORIGIN_AIRPORT_ID').size()\n",
    "filtered_orig_airport_counts = orig_airport_counts[orig_airport_counts >= SINGLE_CONDITIONAL_FILTER]\n",
    "filtered_df = filtered_df[filtered_df['ORIGIN_AIRPORT_ID'].isin(filtered_orig_airport_counts.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for destination airport\n",
    "dest_airport_counts = filtered_df.groupby('DEST_AIRPORT_ID').size()\n",
    "filtered_dest_airport_counts = dest_airport_counts[dest_airport_counts >= SINGLE_CONDITIONAL_FILTER]\n",
    "filtered_df = filtered_df[filtered_df['DEST_AIRPORT_ID'].isin(filtered_dest_airport_counts.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb96780",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "All above filtering logic done, we can now do analysis on this data frame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "383f452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_data_path = \"data/cached_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4997a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cached_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fd933fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index based on the first four columns for quick indexing later\n",
    "CONDITIONAL_COLUMNS = [\n",
    "    'OP_CARRIER_AIRLINE_ID',\n",
    "    'ORIGIN_AIRPORT_ID',\n",
    "    'DEST_AIRPORT_ID',\n",
    "    'DEP_TIME_BUCKET',\n",
    "]\n",
    "df = df.set_index(CONDITIONAL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8ccae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DELAY_COLUMN = 'ARR_DELAY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e348b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60059"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the conditional columns and gather counts\n",
    "grouped = df.groupby(CONDITIONAL_COLUMNS).size()\n",
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of counts in grouped\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(grouped, bins=50, color='b', alpha=0.7)\n",
    "plt.title('Distribution of Flight Counts by Group', fontsize=16)\n",
    "plt.xlabel('Number of Flights', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out how many have size > 200\n",
    "grouped[grouped > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 5 groups\n",
    "top_groups = grouped[grouped > 200].sort_values(ascending=False).head(5)\n",
    "top_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID']).size().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d61fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID']).size().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6293db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for the to group from top_groups and plot the distribution of delays\n",
    "top_group = top_groups.index[0]\n",
    "top_group_df = df.loc[top_group]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(top_group_df[DELAY_COLUMN], bins=50, color='b', alpha=0.7, density=True)\n",
    "plt.title(f\"Distribution of Delays for Top Group: {top_group}\", fontsize=16)\n",
    "plt.xlabel('Delay (minutes)', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_group_df[top_group_df[DELAY_COLUMN] > 0].shape[0] / top_group_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = top_group_df[top_group_df[DELAY_COLUMN] > 0]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(filtered_df[DELAY_COLUMN], bins=50, color='b', alpha=0.7, density=True)\n",
    "plt.title(f\"Distribution of Delays for Top Group: {top_group}\", fontsize=16)\n",
    "plt.xlabel('Delay (minutes)', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b54cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79383e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf879679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b50b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lookup tables for airport\n",
    "AIRPORT_LOOKUP_FILE = os.path.join('stored_data', 'lookup', 'L_AIRPORT_ID.csv')\n",
    "\n",
    "# read the airport lookup table\n",
    "airport_codes = pd.read_csv(AIRPORT_LOOKUP_FILE)\n",
    "airport_codes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_codes = airport_codes.set_index('Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d620a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_counts = df.groupby(['ORIGIN_AIRPORT_ID', 'DEST_AIRPORT_ID']).size().sort_values(ascending=False)\n",
    "\n",
    "# get top 50 travel counts\n",
    "top_travel_counts = travel_counts.head(50)\n",
    "\n",
    "# get the airport description for each origin and dest airport id in top_travel_counts\n",
    "top_travel_counts = top_travel_counts.reset_index()\n",
    "top_travel_counts['ORIGIN_AIRPORT'] = top_travel_counts['ORIGIN_AIRPORT_ID'].map(airport_codes['Description'])\n",
    "top_travel_counts['DEST_AIRPORT'] = top_travel_counts['DEST_AIRPORT_ID'].map(airport_codes['Description'])\n",
    "\n",
    "top_travel_counts = top_travel_counts.drop(columns=[\"ORIGIN_AIRPORT_ID\", \"DEST_AIRPORT_ID\"])\n",
    "top_travel_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52468ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca105c2",
   "metadata": {},
   "source": [
    "## Ranking the Partition of the Four Conditional Variables in terms of Predicting full Conditional Distribution\n",
    "We want an algorithm to model $P(D|C_1, C_2, C_3, C_4)$ the four conditional RVs when there's not enough data support.\n",
    "\n",
    "To do this, we'll use a bayesian approach that assumes independence and conditional independence of certain subsets of $C_i$ with each other.\n",
    "\n",
    "See derivation in whitepaper.\n",
    "\n",
    "In this analysis, we'll take cases where the full conditional distribution has data support. Then, we rank the partitions on how well they model the full distribution. Finally, we average those ranks and rank the paritions based on their average rank score. \n",
    "During inference, we iterate through these partitions in order from highest rank to lowest until feasibility to model the query request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a9f354ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_path = \"app/backend/assets/model_params.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a0fc2888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEP_TIME_BUCKET</th>\n",
       "      <th>p</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353679</td>\n",
       "      <td>0.024523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19393.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400849</td>\n",
       "      <td>0.032757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19687.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345942</td>\n",
       "      <td>0.041299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19690.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.427089</td>\n",
       "      <td>0.046093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.293436</td>\n",
       "      <td>0.025762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.379203</td>\n",
       "      <td>0.020860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19930.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377557</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345463</td>\n",
       "      <td>0.023433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323010</td>\n",
       "      <td>0.017629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540595</td>\n",
       "      <td>0.028692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OP_CARRIER_AIRLINE_ID  ORIGIN_AIRPORT_ID  DEST_AIRPORT_ID DEP_TIME_BUCKET  \\\n",
       "0                    NaN                NaN              NaN             NaN   \n",
       "1                19393.0                NaN              NaN             NaN   \n",
       "2                19687.0                NaN              NaN             NaN   \n",
       "3                19690.0                NaN              NaN             NaN   \n",
       "4                19790.0                NaN              NaN             NaN   \n",
       "5                19805.0                NaN              NaN             NaN   \n",
       "6                19930.0                NaN              NaN             NaN   \n",
       "7                19977.0                NaN              NaN             NaN   \n",
       "8                20046.0                NaN              NaN             NaN   \n",
       "9                20225.0                NaN              NaN             NaN   \n",
       "\n",
       "          p    lambda  \n",
       "0  0.353679  0.024523  \n",
       "1  0.400849  0.032757  \n",
       "2  0.345942  0.041299  \n",
       "3  0.427089  0.046093  \n",
       "4  0.293436  0.025762  \n",
       "5  0.379203  0.020860  \n",
       "6  0.377557  0.035490  \n",
       "7  0.345463  0.023433  \n",
       "8  0.323010  0.017629  \n",
       "9  0.540595  0.028692  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(asset_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2469a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine col names\n",
    "CONDITIONAL_COLUMNS = [\n",
    "    'OP_CARRIER_AIRLINE_ID',\n",
    "    'ORIGIN_AIRPORT_ID',\n",
    "    'DEST_AIRPORT_ID',\n",
    "    'DEP_TIME_BUCKET',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b26ae722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 'Int64' type for OP_CARRIER_AIRLINE_ID\n",
    "df['OP_CARRIER_AIRLINE_ID'] = df['OP_CARRIER_AIRLINE_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d041f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(CONDITIONAL_COLUMNS, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15529bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for where the conditional columns are not NaN\n",
    "fully_available_df = df.dropna(subset=CONDITIONAL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d4ff463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16740"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fully_available_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56dc5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayesian_parameters(subset_params: np.ndarray, margin_params: np.ndarray) -> np.ndarray:\n",
    "    num_subsets = len(subset_params)\n",
    "\n",
    "    assert num_subsets > 0\n",
    "\n",
    "    margin_lambda, margin_p = margin_params[0], margin_params[1]\n",
    "\n",
    "    new_lambda = np.sum(subset_params[:, 0]) - margin_lambda * (num_subsets - 1)\n",
    "    new_p = np.prod(subset_params[:, 0] * subset_params[:, 1]) / (margin_p * margin_lambda) ** (num_subsets - 1)\n",
    "    new_p = new_p / new_lambda\n",
    "\n",
    "    return np.array([new_lambda, new_p])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f27554f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(params_a: np.ndarray, params_b: np.ndarray) -> float:\n",
    "    lambda_a, p_a = params_a[0], params_a[1]\n",
    "    lambda_b, p_b = params_b[0], params_b[1]\n",
    "\n",
    "    lambda_contribution = (lambda_b - lambda_a) * np.log(lambda_a / lambda_b)\n",
    "    p_contribution = p_a * np.log(p_a / p_b)\n",
    "    return lambda_contribution * p_contribution / lambda_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "796a64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition class of the four conditional columns\n",
    "class Partition:\n",
    "    def __init__(self, col_part: list) -> None:\n",
    "        print(col_part)\n",
    "        self.col_part = tuple(sorted(tuple(sorted(part) for part in col_part)))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return repr(self.col_part)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d238c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def generate_partitions(arr: List[str]) -> List[List[str]]:\n",
    "    if len(arr) == 1:\n",
    "        return [[arr]]\n",
    "\n",
    "    curr_elem = arr[0]\n",
    "    next_partitions = generate_partitions(arr[1:])\n",
    "\n",
    "    partitions = []\n",
    "    for partition in next_partitions:\n",
    "        for i, part in enumerate(partition):\n",
    "            new_partition = partition.copy()\n",
    "            new_partition[i] = part + [curr_elem]\n",
    "            partitions.append(new_partition)\n",
    "        partitions.append(partition + [[curr_elem]])\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f9599d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_partitions_obj(arr: List[str]) -> List[Partition]:\n",
    "    partitions = generate_partitions(arr)\n",
    "    return [Partition(part) for part in partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f33fa808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID']]\n",
      "[['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'ORIGIN_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID'], ['DEST_AIRPORT_ID']]\n",
      "[['DEP_TIME_BUCKET', 'ORIGIN_AIRPORT_ID'], ['DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'ORIGIN_AIRPORT_ID'], ['DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'OP_CARRIER_AIRLINE_ID'], ['DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID']]\n",
      "[['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET', 'OP_CARRIER_AIRLINE_ID'], ['DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID']]\n",
      "[['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID']]\n",
      "[['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']]\n",
      "[['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partitions = generate_partitions_obj(CONDITIONAL_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f18af626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID'],),\n",
       " (['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']),\n",
       " (['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET', 'DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET', 'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID'], ['DEST_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET', 'ORIGIN_AIRPORT_ID'], ['DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID']),\n",
       " (['DEP_TIME_BUCKET', 'ORIGIN_AIRPORT_ID'], ['DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']),\n",
       " (['DEP_TIME_BUCKET', 'OP_CARRIER_AIRLINE_ID'], ['DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'ORIGIN_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID']),\n",
       " (['DEP_TIME_BUCKET', 'OP_CARRIER_AIRLINE_ID'], ['DEST_AIRPORT_ID'], ['ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID', 'OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID', 'ORIGIN_AIRPORT_ID']),\n",
       " (['DEP_TIME_BUCKET'], ['DEST_AIRPORT_ID'], ['OP_CARRIER_AIRLINE_ID'], ['ORIGIN_AIRPORT_ID'])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6e2d7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_df = df.loc[(None, None, None, None)]\n",
    "margin_lambda = margin_df['lambda']\n",
    "margin_p = margin_df['p']\n",
    "\n",
    "margin_params = np.array([margin_lambda, margin_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "29ed0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_to_rank_lst = {\n",
    "    part: [] for part in partitions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98cc7238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEP_TIME_BUCKET</th>\n",
       "      <th>p</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OP_CARRIER_AIRLINE_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>DEST_AIRPORT_ID</th>\n",
       "      <th>DEP_TIME_BUCKET</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">19393</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">10140.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10423.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>19393</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>10423.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.527105</td>\n",
       "      <td>0.032816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>19393</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>10423.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.312318</td>\n",
       "      <td>0.042235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>19393</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.507719</td>\n",
       "      <td>0.035650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10821.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>19393</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>10821.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.604414</td>\n",
       "      <td>0.028819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11259.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>19393</td>\n",
       "      <td>10140.0</td>\n",
       "      <td>11259.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.480273</td>\n",
       "      <td>0.030137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21167</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">14893.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">12892.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>21167</td>\n",
       "      <td>14893.0</td>\n",
       "      <td>12892.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.379509</td>\n",
       "      <td>0.028483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>21167</td>\n",
       "      <td>14893.0</td>\n",
       "      <td>12892.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.301451</td>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14747.0</th>\n",
       "      <th>morning</th>\n",
       "      <td>21167</td>\n",
       "      <td>14893.0</td>\n",
       "      <td>14747.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.390135</td>\n",
       "      <td>0.028837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14908.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">14747.0</th>\n",
       "      <th>afternoon</th>\n",
       "      <td>21167</td>\n",
       "      <td>14908.0</td>\n",
       "      <td>14747.0</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>0.362881</td>\n",
       "      <td>0.016069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>21167</td>\n",
       "      <td>14908.0</td>\n",
       "      <td>14747.0</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.335561</td>\n",
       "      <td>0.017760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16740 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         OP_CARRIER_AIRLINE_ID  \\\n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET                          \n",
       "19393                 10140.0           10423.0         afternoon                        19393   \n",
       "                                                        morning                          19393   \n",
       "                                        10800.0         afternoon                        19393   \n",
       "                                        10821.0         afternoon                        19393   \n",
       "                                        11259.0         afternoon                        19393   \n",
       "...                                                                                        ...   \n",
       "21167                 14893.0           12892.0         afternoon                        21167   \n",
       "                                                        morning                          21167   \n",
       "                                        14747.0         morning                          21167   \n",
       "                      14908.0           14747.0         afternoon                        21167   \n",
       "                                                        morning                          21167   \n",
       "\n",
       "                                                                         ORIGIN_AIRPORT_ID  \\\n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET                      \n",
       "19393                 10140.0           10423.0         afternoon                  10140.0   \n",
       "                                                        morning                    10140.0   \n",
       "                                        10800.0         afternoon                  10140.0   \n",
       "                                        10821.0         afternoon                  10140.0   \n",
       "                                        11259.0         afternoon                  10140.0   \n",
       "...                                                                                    ...   \n",
       "21167                 14893.0           12892.0         afternoon                  14893.0   \n",
       "                                                        morning                    14893.0   \n",
       "                                        14747.0         morning                    14893.0   \n",
       "                      14908.0           14747.0         afternoon                  14908.0   \n",
       "                                                        morning                    14908.0   \n",
       "\n",
       "                                                                         DEST_AIRPORT_ID  \\\n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET                    \n",
       "19393                 10140.0           10423.0         afternoon                10423.0   \n",
       "                                                        morning                  10423.0   \n",
       "                                        10800.0         afternoon                10800.0   \n",
       "                                        10821.0         afternoon                10821.0   \n",
       "                                        11259.0         afternoon                11259.0   \n",
       "...                                                                                  ...   \n",
       "21167                 14893.0           12892.0         afternoon                12892.0   \n",
       "                                                        morning                  12892.0   \n",
       "                                        14747.0         morning                  14747.0   \n",
       "                      14908.0           14747.0         afternoon                14747.0   \n",
       "                                                        morning                  14747.0   \n",
       "\n",
       "                                                                        DEP_TIME_BUCKET  \\\n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET                   \n",
       "19393                 10140.0           10423.0         afternoon             afternoon   \n",
       "                                                        morning                 morning   \n",
       "                                        10800.0         afternoon             afternoon   \n",
       "                                        10821.0         afternoon             afternoon   \n",
       "                                        11259.0         afternoon             afternoon   \n",
       "...                                                                                 ...   \n",
       "21167                 14893.0           12892.0         afternoon             afternoon   \n",
       "                                                        morning                 morning   \n",
       "                                        14747.0         morning                 morning   \n",
       "                      14908.0           14747.0         afternoon             afternoon   \n",
       "                                                        morning                 morning   \n",
       "\n",
       "                                                                                p  \\\n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET             \n",
       "19393                 10140.0           10423.0         afternoon        0.527105   \n",
       "                                                        morning          0.312318   \n",
       "                                        10800.0         afternoon        0.507719   \n",
       "                                        10821.0         afternoon        0.604414   \n",
       "                                        11259.0         afternoon        0.480273   \n",
       "...                                                                           ...   \n",
       "21167                 14893.0           12892.0         afternoon        0.379509   \n",
       "                                                        morning          0.301451   \n",
       "                                        14747.0         morning          0.390135   \n",
       "                      14908.0           14747.0         afternoon        0.362881   \n",
       "                                                        morning          0.335561   \n",
       "\n",
       "                                                                           lambda  \n",
       "OP_CARRIER_AIRLINE_ID ORIGIN_AIRPORT_ID DEST_AIRPORT_ID DEP_TIME_BUCKET            \n",
       "19393                 10140.0           10423.0         afternoon        0.032816  \n",
       "                                                        morning          0.042235  \n",
       "                                        10800.0         afternoon        0.035650  \n",
       "                                        10821.0         afternoon        0.028819  \n",
       "                                        11259.0         afternoon        0.030137  \n",
       "...                                                                           ...  \n",
       "21167                 14893.0           12892.0         afternoon        0.028483  \n",
       "                                                        morning          0.030914  \n",
       "                                        14747.0         morning          0.028837  \n",
       "                      14908.0           14747.0         afternoon        0.016069  \n",
       "                                                        morning          0.017760  \n",
       "\n",
       "[16740 rows x 6 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_available_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a451c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled (both index and columns) DataFrame objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z8/1d183zgx3c11zg5s3n3byg700000gn/T/ipykernel_48715/1279705277.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_part\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# filter df for the partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mexcluded_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONDITIONAL_COLUMNS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mpart_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcluded_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# extract out the p, lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpart_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/flight_analysis/venv/flight/lib/python3.11/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/flight_analysis/venv/flight/lib/python3.11/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/flight_analysis/venv/flight/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7895\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# only relevant for Series other case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7897\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7899\u001b[0m         \u001b[0;31m# See GH#4537 for discussion of scalar op behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7900\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_frame_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/flight_analysis/venv/flight/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[1;32m   8192\u001b[0m                     left, right = left.align(\n\u001b[1;32m   8193\u001b[0m                         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8194\u001b[0m                     )\n\u001b[1;32m   8195\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8196\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   8197\u001b[0m                         \u001b[0;34m\"Can only compare identically-labeled (both index and columns) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8198\u001b[0m                         \u001b[0;34m\"DataFrame objects\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8199\u001b[0m                     )\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled (both index and columns) DataFrame objects"
     ]
    }
   ],
   "source": [
    "# iterate through all fully available data\n",
    "for _, row in fully_available_df.iterrows():\n",
    "    print(type(row))\n",
    "    # get the p, lambda\n",
    "    full_p, full_lambda = row['p'], row['lambda']\n",
    "\n",
    "    # iterate through the partitions, derive the partition params, and compute its KL\n",
    "    part_kl_scores = []  # tuple of part, kl_score\n",
    "    for part in partitions:\n",
    "        # gather the parameters for the partition\n",
    "        part_params = []\n",
    "        for subset in part.col_part:\n",
    "            # filter df for the partition\n",
    "            excluded_cols = list(set(CONDITIONAL_COLUMNS) - set(subset))\n",
    "            part_row = df[df[subset] == row[subset] & df[excluded_cols].isna()]\n",
    "\n",
    "            # extract out the p, lambda\n",
    "            part_p, part_lambda = part_row['p'], part_row['lambda']\n",
    "            part_params.append([part_lambda, part_p])\n",
    "\n",
    "        # compute the new p, lambda\n",
    "        new_params = compute_bayesian_parameters(np.array(part_params), margin_params)\n",
    "\n",
    "        # compute the kl divergence\n",
    "        kl_score = kl_divergence([full_lambda, full_p], new_params)\n",
    "\n",
    "        part_kl_scores.append((part, kl_score))\n",
    "    \n",
    "    # sort by score\n",
    "    part_kl_scores.sort(key=lambda x: x[1])\n",
    "\n",
    "    # append to the partition_to_rank_lst\n",
    "    for i, (part, kl_score) in enumerate(part_kl_scores):\n",
    "        partition_to_rank_lst[part].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13423451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
